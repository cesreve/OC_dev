# -*- coding: utf-8 -*-
"""beautiful_soup_scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10z89l_uMLKmuqthTBfn3VFHh4gm3NhsJ

http://books.toscrape.com/   
https://coreyms.com/
"""

pip install beautifulsoup4

pip install lxml

pip install html5lib

pip install requests

from bs4 import BeautifulSoup
import requests
import time

req = requests.get('http://books.toscrape.com/')
soup = BeautifulSoup(req.text, "lxml")

nav_list = soup.find('ul',class_='nav nav-list')

categories = nav_list.find('ul')

for l in categories.find_all('li'):
  print(l.a.text.strip())

books = soup.find('ol', class_='row')

for titre in books.find_all('h3'):
  print(titre.a['title'])

for article, i in zip(soup.find_all('article', class_='product_pod'), range(5)):
  print(article.h3.a['href'])

for article, i in zip(soup.find_all('article', class_='product_pod'), range(5)):
  print(article.h3.a)

i= 0
while True:
  i+=1
  print(f'http://books.toscrape.com/catalogue/page-{i}.html')
  req = requests.get(f'http://books.toscrape.com/catalogue/page-{i}.html')
  soup = BeautifulSoup(req.text, "lxml")

  for article, j in zip(soup.find_all('article', class_='product_pod'), range(3)):
    target = article.h3.a['href']
    link = f'http://books.toscrape.com/catalogue/{target}'
    print(link)
    req_book = requests.get(link)
    book_page = BeautifulSoup(req_book.text, "lxml")
    result = book_page.find('table', class_='table table-striped')
    print((result.find('tr').th).text, (result.find('tr').td).text)
    # for l in result.find('tr'):
    #   print(l.td)
  if i > 3:
    break

i= 0
while True:
  i+=1
  print(f'http://books.toscrape.com/catalogue/page-{i}.html')
  req = requests.get(f'http://books.toscrape.com/catalogue/page-{i}.html')
  soup = BeautifulSoup(req.text, "lxml")

  for article, j in zip(soup.find_all('article', class_='product_pod'), range(3)):
    target = article.h3.a['href']
    link = f'http://books.toscrape.com/catalogue/{target}'
    print(link)
    req_book = requests.get(link)
    book_page = BeautifulSoup(req_book.text, "lxml")
    result = book_page.find('table', class_='table table-striped')
    for detail in result.find_all('tr'):
      print(detail.th.text, detail.td.text)
      #print((result.find('tr').th).text, (result.find('tr').td).text)
    # for l in result.find('tr'):
    #   print(l.td)
  if i > 3:
    break



